#******************************************************************************
# Modifications Copyright (c) 2023 Advanced Micro Devices, Inc.
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
# 1. Redistributions of source code must retain the above copyright notice,
# this list of conditions and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright notice,
# this list of conditions and the following disclaimer in the documentation
# and/or other materials provided with the distribution.
# 3. Neither the name of the copyright holder nor the names of its contributors
# may be used to endorse or promote products derived from this software without
# specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.
#
#******************************************************************************

from torch import Tensor, memory_format
from typing import Callable, Optional, List, overload, Tuple, Union
from torch.types import _bool, _dtype, _device

# Defined in tools/autograd/templates/python_nn_functions.cpp

${dispatched_hints}

# Defined in aten/src/ATen/native/mkldnn/Linear.cpp
def mkldnn_linear(input: Tensor, weight: Tensor, bias: Optional[Tensor]) -> Tensor: ...

# Defined at aten/src/ATen/native/mkldnn/MKLDNNConversions.cpp
def mkldnn_reorder_conv2d_weight(self: Tensor, padding: List, stride: List, dilatation: List, groups: int) -> Tensor: ...
def mkldnn_reorder_conv3d_weight(self: Tensor, padding: List, stride: List, dilatation: List, groups: int) -> Tensor: ...

# Defined in aten/src/ATen/native/mkldnn/Prelu.cpp
def mkldnn_prelu(input: Tensor, weight: Tensor) -> Tensor: ...

# Defined in aten/src/ATen/native/zendnn/Prelu.cpp
def zendnn_prelu(input: Tensor, weight: Tensor) -> Tensor: ...

# Defined at aten/src/ATen/native/zendnn/ZENDNNConversions.cpp
def zendnn_reorder_conv2d_weight(self: Tensor, padding: List, stride: List, dilatation: List, groups: int) -> Tensor: ...
def zendnn_reorder_conv3d_weight(self: Tensor, padding: List, stride: List, dilatation: List, groups: int) -> Tensor: ...

# Defined at aten/src/ATen/native/zendnn/ConvFusion.cpp
def zendnn_vitisai_convolution(self: Tensor, weight: Tensor, bias: Optional[Tensor], padding: Union[str, Tuple[int, ...]], stride: Tuple[int, ...], dilation: Tuple[int, ...], groups: int, dequant: bool, fuse_relu: bool, input_scale: int, filter_scale: int, output_scale: int) -> Tensor: ...

# Defined at aten/src/ATen/native/zendnn/Linear.cpp
def zendnn_vitisai_linear(self: Tensor, weight: Tensor, bias: Optional[Tensor], dequant: bool, fuse_relu: bool, input_scale: int, filter_scale: int, output_scale: int) -> Tensor: ...

# Defined at tools/autograd/templates/python_nn_functions.cpp
@overload
def _parse_to(device: _device, dtype: _dtype, non_blocking: _bool, copy: _bool, *,
              memory_format: memory_format) -> Tuple[_device, _dtype, _bool, memory_format]: ...
@overload
def _parse_to(dtype: _dtype, non_blocking: _bool, copy: _bool, *,
              memory_format: memory_format) -> Tuple[_device, _dtype, _bool, memory_format]: ...
@overload
def _parse_to(tensor: Tensor, non_blocking: _bool, copy: _bool, *,
              memory_format: memory_format) -> Tuple[_device, _dtype, _bool, memory_format]: ...

# Defined in aten/src/ATen/naitve/PadSequence.cpp
def pad_sequence(sequences: List[Tensor], batch_first: bool = False,
                 padding_value: float = ...) -> Tensor: ...

def flatten_dense_tensors(tensors: List[Tensor]) -> Tensor: ...

def unflatten_dense_tensors(flat: Tensor, tensors: List[Tensor]) -> List[Tensor]: ...
